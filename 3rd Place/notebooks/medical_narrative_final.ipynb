{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a230eb3c-6e70-48cb-9a5b-5311256ce712",
   "metadata": {},
   "source": [
    "### Install\n",
    "1. conda create --name fall  python=3.9\n",
    "2. conda activate fall\n",
    "3.   pip install -r requirements.txt\n",
    "##### Ubuntu\n",
    "4. conda install -c pytorch faiss-cpu\n",
    "##### windows  \n",
    "4. conda install -c conda-forge faiss\n",
    "\n",
    "(using the other conda channel in Windows causes missing dlls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5008240b-853f-4d08-9a62-8dd0059b04aa",
   "metadata": {},
   "source": [
    "### Introduction: Medical Narrative Mining\n",
    "\n",
    "The objective of this compitition is to mine the narrative field of medical records to reveal insights into old age(65+) falls.\n",
    "The tabular data provided, are extracted from the National Electronic Injury Surveillance System (NEISS) and contains key features such as age, sex, race, date, location, product involved, body_part, diagnosis and disposition. However precipitating activity is absent. This feature along with some other possibly useful atrribute are to be extracted and analysed from the narratives(400 max charecter) for insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c151ba-538b-4a4d-866b-58eaf17562ef",
   "metadata": {},
   "source": [
    "To facilitate mining the narrative field we first dig into the NEISS coding manual which sets rules and guidelines for how the narrative filed is to be written. For us the most relevant aspect is the guideline to:\n",
    "\"Describe the sequence of events, alcohol/drug involvement, and the affected body part(s) in the middle of the comment\" and \"relevant clinician’s diagnoses should be at the end of the comment\". The sequence of event implies precipitating event to be in the first sentence. So ideally if three sentences are given in sequences we can expect the precipitating event to be on the first sentence but this is seldom the case. However the word \"And\" or \"&\" is used often as event seperator and this we can use. According to the manual 's/p' and 'after' are mentioned explicitly to be used as event seperator which also we use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d40e32-3578-45a1-aec0-634d88f44792",
   "metadata": {},
   "source": [
    "Keyword \"Slipped and Fell\" and \"Tripped and Fell\" along with their abbreviation \"s'd&f\" and \"t'd&f\" are explicitly mentioned in the manual to be used in describing the said event. These are found with high frequency in the narratives( as will be shown) and could be directly searched for their occurences using keyword search. Besides these, there are other activity or event such as walking or getting up that causes a fall. Only doing keyword search is inefficient and could lead to wrong distribution.\n",
    "\n",
    "So We apply semantic search using FAISS (Facebook AI Similarity Search) for querying our vector store(embeddings of all narratives in primary.csv computed via OpenAI’s text-embedding-ada-002 model and provided by competition host). How we formulate the query and group our activity class(precipitating event) requires carefull consideration, given the dataset(with already extracted attrubutes) and how the narrative is structured.\n",
    "\n",
    "First We will load our data along with narrative embedding to FAISS. As we will be performing 'range search', we will also be using only the 'cpu' as 'gpu' is unsupported for this operation.\n",
    "\n",
    "Given a query, 'Range Search' returns all instances in the vector store below a threshold computed using a distance metric between the query embedding and value embedding in the vector store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6abe284-51eb-48bf-a03b-0f89b2b10a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Major imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import faiss\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "import openTSNE\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, ndcg_score, davies_bouldin_score\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", rc={'figure.figsize':(16, 8)})\n",
    "import networkx as nx\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from typing import Dict\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(13)\n",
    "\n",
    "tqdm.pandas()\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e969b9ee-205d-4a99-b2a7-4c5f436cd321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/emily/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/emily/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/emily/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk downloads\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75eddf0-f09d-4a0e-820e-878a20107ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dataset, set path according to your folder and file structure\n",
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "\n",
    "primary_path = DATA_DIR / 'raw/primary_data.csv'\n",
    "variable_mapping = DATA_DIR / 'raw/variable_mapping.json'\n",
    "embedding_path = DATA_DIR / 'raw/openai_embeddings_primary_narratives.parquet.gzip'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe24a9",
   "metadata": {},
   "source": [
    "<span style='color:red'>YOU MUST SET AN OPENAI KEY BELOW IN VARIABLE openai_key_uk</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd8e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your key here\n",
    "openai_key_uk ='' #<your-key>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0dd543e-a21f-4554-aa71-2dad6f319f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These three files are required..\n",
      "primary_path exists= True\n",
      "variable_mapping exists= True\n",
      "embedding_path exists= True\n"
     ]
    }
   ],
   "source": [
    "print ('These three files are required..')\n",
    "print ('primary_path exists=', os.path.isfile(primary_path))\n",
    "print ('variable_mapping exists=', os.path.isfile(variable_mapping))\n",
    "print ('embedding_path exists=', os.path.isfile(embedding_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b70994-199b-4542-851f-63b1581607e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and embeddings\n",
    "with Path(variable_mapping).open(\"r\") as f:\n",
    "        mapping = json.load(f, parse_int=True)\n",
    "\n",
    "# Load primary data converting the catagorical representation to string description\n",
    "def load_primary(path):\n",
    "    df = pd.read_csv(path,\n",
    "                     # set columns that can be null to nullable ints\n",
    "                     dtype={\"body_part_2\": \"Int64\", \"diagnosis_2\": \"Int64\"})\n",
    "    # convert the encoded values in the mapping to integers since they get read in as strings\n",
    "    for c in mapping.keys():\n",
    "        mapping[c] = {int(k): v for k, v in mapping[c].items()}\n",
    "    for col in mapping.keys():\n",
    "        df[col] = df[col].map(mapping[col])\n",
    "        \n",
    "    # The string representation has the integer key at the start, lets remove them. \n",
    "    for col in ['body_part', 'body_part_2', 'diagnosis', 'diagnosis_2', 'product_1', 'disposition']:\n",
    "        df[col] = df[col].apply(lambda x: x.split(' - ')[1].lower().strip(' ') if isinstance(x, str) else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e17779c-6dd9-48bf-bfe3-a42f2c5dda4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                           115128\n",
      "unique                             496\n",
      "top       floors or flooring materials\n",
      "freq                             33204\n",
      "Name: product_1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# load the primary tabular data and narrative embeddings to FAISS\n",
    "df = load_primary(primary_path)\n",
    "print (df.product_1.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f3c772-c42d-4ea4-8078-280b9caf1279",
   "metadata": {},
   "source": [
    "While activity can be precisely defined, we first broadly visualize activities into heirarchical classes for our query construction to be passed using range search; the figure below shows such categorization. This will enable us to find the related index for better analysis of the underlying distribution.\n",
    "\n",
    "![Activity Category](images/activity.drawio.png)\n",
    "\n",
    "Query construction should be semantically rich and informative for semantic search. As such only providing the activity such as 'getting up' or 'sitting down' is insufficient, but by providing context such as 'chair' or 'stairs', we provide clearer semantics. For example, consider 'getting up a chair' which implies a person starting from a sitting position to a standing position versus 'getting up a stair' that implies a person starting from a standing position to a climbing state. These two instances are different activity although sharing the same common word i.e \"getting up\". Similarly 'slipped' is a result of \n",
    "wet surface while tripped is caused by obstacles. The two can have different outcome to final diagnostics, 'Slipped' could\n",
    "lead to more back of the head injuries while 'Tripped' would cause more frontal injuries due to involutary forwad motion.\n",
    "\n",
    "Thus, we associate an action with product for a meaningful semantic search. There are 496 unique product in 'product_1' column in primary data but we can narrow them to a few distinct and highly occuring items, and let the semantic search match similar product. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae28f3b3-1dea-44c4-b5fd-61acc2553f10",
   "metadata": {},
   "source": [
    "Because of the concise style of writing due to the maximum allowed charectar imposed, along with the use of abbreviation in narratives, query construction is tricky. Getting up a stair is different from getting up a couch. Apart from the product the words are similar.\n",
    "\n",
    "So first let us get a handle on words(verb) to specify activity along with combinations with product to form context in describing precipitating events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e02315fc-230e-4819-b927-9500316bf12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define globally some key variables to be used through out the data exploratoin\n",
    "import multiprocessing as m\n",
    "from nltk.corpus import stopwords \n",
    "import re\n",
    "# Medical Terms obtained from community code https://www.drivendata.org/competitions/217/cdc-fall-narratives/community-code/13/\n",
    "medical_terms = {\n",
    "    \"&\": \"and\",\n",
    "    \"***\": \"\",\n",
    "    \">>\": \"clinical diagnosis\",\n",
    "    \"@\": \"at\",\n",
    "    \"abd\": \"abdomen\",\n",
    "    \"af\": \"accidental fall\",\n",
    "    \"afib\": \"atrial fibrillation\",\n",
    "    \"aki\": \"acute kidney injury\",\n",
    "    \"am\": \"morning\",\n",
    "    \"ams\": \"altered mental status\",\n",
    "    \"bac\": \"blood alcohol content\",\n",
    "    \"bal\": \"blood alcohol level,\",\n",
    "    \"biba\": \"brought in by ambulance\",\n",
    "    \"c/o\": \"complains of\",\n",
    "    \"chi\": \"closed-head injury\",\n",
    "    \"clsd\": \"closed\",\n",
    "    \"cpk\": \"creatine phosphokinase\",\n",
    "    \"cva\": \"cerebral vascular accident\",\n",
    "    \"dx\": \"clinical diagnosis\",\n",
    "    \"ecf\": \"extended-care facility\",\n",
    "    \"er\": \"emergency room\",\n",
    "    \"etoh\": \"ethyl alcohol\",\n",
    "    \"eval\": \"evaluation\",\n",
    "    \"fd\": \"fall detected\",\n",
    "    \"fx\": \"fracture\",\n",
    "    \"fxs\": \"fractures\",\n",
    "    \"glf\": \"ground level fall\",\n",
    "    \"h/o\": \"history of\",\n",
    "    \"htn\": \"hypertension\",\n",
    "    \"hx\": \"history of\",\n",
    "    \"inj\": \"injury\",\n",
    "    \"inr\": \"international normalized ratio\",\n",
    "    \"intox\": \"intoxication\",\n",
    "    \"l\": \"left\",\n",
    "    \"loc\": \"loss of consciousness\",\n",
    "    \"lt\": \"left\",\n",
    "    \"mech\": \"mechanical\",\n",
    "    \"mult\": \"multiple\",\n",
    "    \"n.h.\": \"nursing home\",\n",
    "    \"nh\": \"nursing home\",\n",
    "    \"p/w\": \"presents with\",\n",
    "    \"pm\": \"afternoon\",\n",
    "    \"pt\": \"patient\",\n",
    "    \"pta\": \"prior to arrival\",\n",
    "    \"pts\": \"patient's\",\n",
    "    \"px\": \"physical examination\", # not \"procedure\",\n",
    "    \"r\": \"right\",\n",
    "    \"r/o\": \"rules out\",\n",
    "    \"rt\": \"right\",\n",
    "    \"s'd&f\": \"slipped and fell\",\n",
    "    \"s/p\": \"after\",\n",
    "    \"sah\": \"subarachnoid hemorrhage\",\n",
    "    \"sdh\": \"acute subdural hematoma\",\n",
    "    \"sts\": \"sit-to-stand\",\n",
    "    \"t'd&f\": \"tripped and fell\",\n",
    "    \"tr\": \"trauma\",\n",
    "    \"uti\": \"urinary tract infection\",\n",
    "    \"w/\": \"with\",\n",
    "    \"w/o\": \"without\",\n",
    "    \"wks\": \"weeks\"\n",
    "}\n",
    "\n",
    "# define unique occurences of body_part\n",
    "body_part = [item.split('-')[1].strip(' ').lower() for item in mapping['body_part'].values()]\n",
    "# define unique occurences of location\n",
    "location = [item.lower() for item in mapping['location'].values()]\n",
    "# define unique occurences of product\n",
    "# additinally we split then concat the product part, as similar product delineated by space are given. \n",
    "product = [item.split('-')[1].strip(' ').lower() for item in mapping['product_1'].values()]\n",
    "product = [item.strip('(').strip(')') for item in set(np.concatenate([item.split(' ') for item in product]))]\n",
    "product = [item for item in product if item!='']\n",
    "\n",
    "def add_body_part_to_stop_words(stop_words):   \n",
    "    for w in body_part:\n",
    "        stop_words.add(str(w))\n",
    "    return stop_words\n",
    "\n",
    "def add_location_to_stop_words(stop_words): \n",
    "    for w in location:\n",
    "        stop_words.add(str(w))\n",
    "    return stop_words\n",
    "\n",
    "def add_product_to_stop_words(stop_words):\n",
    "    for w in product:\n",
    "        w = w.replace(',', '').replace(' ', '')\n",
    "        stop_words.add(str(w))\n",
    "    return stop_words\n",
    "\n",
    "# stop words from nltk used for cleaning the narrative to a cleaner and concise text of precipitating event\n",
    "# we do this so that embeddings from cleaner text can be obtained for evaluating cluster metrics.\n",
    "stop_words_base = set(stopwords.words('english'))\n",
    "# lets remove a few stop words that we know will be used in the narrative \n",
    "# which has impact on the overal semantics of the event\n",
    "for w in ['up', 'down', 'out', 'of' , 'on']:\n",
    "    stop_words_base.remove(w)\n",
    "# These we want to add to the stop words for removal \n",
    "for w in ['was', 'while']:\n",
    "    stop_words_base.add(w)\n",
    "    \n",
    "# slipped and tripped are explicitly used to describe events \n",
    "# so we can define it here for simply looking up its occurence\n",
    "# when a slip or trip event occurs but is not matched as hard coded here, they are \n",
    "# nevertheless found by semantic search.\n",
    "# slipped \n",
    "sp = {\"s'd&f\": [\"slipped and fell\", 'slip and fall', 'slipped'],\n",
    "        \"s/p\": \"after\"}\n",
    "# tripped\n",
    "td = {\"t'd&f\": [\"tripped and fell\", 'trip and fall', 'tripped']}\n",
    "\n",
    "# sentence tokenizer\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "sent_tokenizer._params.abbrev_types.update(['AND', 'and'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d7f6ece-3a87-4103-971e-6930c31467b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The narrative cleaning function is borrowed from community code \n",
    "# https://www.drivendata.org/competitions/217/cdc-fall-narratives/community-code/13/\n",
    "# then modified to further remove stop words(from nltk), along with body_part, location, product as required.\n",
    "# We can also filter words that are not a verb or some words we want to explicitly remove.\n",
    "\n",
    "def clean_narrative_semantics(text, stopwords, filter_vb=None, filter_words=[]):\n",
    "    # lowercase everything=\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    # unglue DX\n",
    "    regex_dx = r\"([ˆ\\W]*(dx)[ˆ\\W]*)\"\n",
    "    text = re.sub(regex_dx, r\". dx: \", text)\n",
    "\n",
    "    # remove age and sex identifications\n",
    "    ## regex to capture age and sex (not perfect but captures almost all of the cases)\n",
    "    regex_age_sex = r\"(\\d+)\\s*?(yof|yf|yo\\s*female|yo\\s*f|yom|ym|yo\\s*male|yo\\s*m)\"\n",
    "    age_sex_match = re.search(regex_age_sex, text)\n",
    "\n",
    "    ## format age and sex\n",
    "    if age_sex_match:\n",
    "        age = age_sex_match.group(1)\n",
    "        sex = age_sex_match.group(2)\n",
    "        \n",
    "        # probably not best practice but it works with this data\n",
    "        if \"f\" in sex:\n",
    "            #text = text.replace(age_sex_match.group(0), f\"{age} years old female\")\n",
    "            text = text.replace(age_sex_match.group(0), f\"patient\")\n",
    "        elif \"m\" in sex:\n",
    "            #text = text.replace(age_sex_match.group(0), f\"{age} years old male\")\n",
    "            text = text.replace(age_sex_match.group(0), f\"patient\")\n",
    "    \n",
    "    # translate medical terms\n",
    "    for term, replacement in medical_terms.items():\n",
    "        if term == \"@\" or term == \">>\" or term == \"&\" or term == \"***\":\n",
    "            pattern = fr\"({re.escape(term)})\"\n",
    "            text = re.sub(pattern, f\" {replacement} \", text) # force spaces around replacement\n",
    "            \n",
    "        else:\n",
    "            pattern = fr\"(?<!-)\\b({re.escape(term)})\\b(?!-)\"\n",
    "            text = re.sub(pattern, replacement, text)\n",
    "\n",
    "    # user-friendly format\n",
    "    text = text.lower()\n",
    "    text = text.replace('patient ', '')\n",
    "    if \"s'd and f\" in text:\n",
    "        return 'slipped and fell'\n",
    "    for v in sp[\"s'd&f\"]:\n",
    "        if v in text:\n",
    "            return 'slipped and fell'\n",
    "    if \"t'd and f\" in text:\n",
    "        return 'tripped and fell'\n",
    "    for v in td[\"t'd&f\"]:\n",
    "        if v in text:\n",
    "            return 'tripped and fell'\n",
    "    \n",
    "    # 'and' is used as seperator of actions(precipitating event, fall, diagnosis) so we use at as sentence delimitor\n",
    "    # so that we can get the first sentence where the precipitating event should be found\n",
    "    text = text.replace(' and', '.').replace('&', '.')\n",
    "    sentences = sent_tokenizer.tokenize(text)\n",
    "        \n",
    "    len_sentences = len(sentences)\n",
    "    if len_sentences==1:\n",
    "        return 'not mentioned'\n",
    "    \n",
    "    sent_first = None\n",
    "    # 's/p' and 'after are shorthand that the coding manual explicitly recommends to be used as seperators\n",
    "    for sent in sentences:\n",
    "        if 's/p' in sent:\n",
    "            sent_first = sent.split('s/p')[1]\n",
    "            break\n",
    "        if 'after' in sent:\n",
    "            sent_first = sent.split('after')[1]\n",
    "            break\n",
    "    \n",
    "    sent_first = sentences[0].replace('.','') if sent_first is None else sent_first\n",
    "    \n",
    "    # filter stop words\n",
    "    filtered_sent = []\n",
    "    for r in sent_first.split(' '):\n",
    "        r = r.replace(',', '').replace(' ','')\n",
    "        if not r in stopwords:\n",
    "            filtered_sent.append(r)\n",
    "            \n",
    "    # filter verbs\n",
    "    filtered_sent_vb = []\n",
    "    if filter_vb:\n",
    "        for item in filtered_sent:\n",
    "            tag = pos_tag([item.capitalize()])[0]\n",
    "            if tag[1] in filter_vb:\n",
    "                filtered_sent_vb.append(item)\n",
    "        filtered_sent = filtered_sent_vb\n",
    "    \n",
    "    # filter user supplied(anything else that may remain) words\n",
    "    filter_temp = []\n",
    "    for item in filtered_sent:\n",
    "        if not item in filter_words:\n",
    "            filter_temp.append(item)\n",
    "            \n",
    "    filtered_sent = filter_temp\n",
    "    filtered_sent  = filtered_sent  = re.sub(' +', ' ', \" \".join(filtered_sent).replace('.','').strip())\n",
    "    return filtered_sent\n",
    "\n",
    "\n",
    "# randomly pick samples to show i.e comparate narrative to cleaned text\n",
    "def show_samples(df, n =5, col='text'):\n",
    "    for item in df.sample(n).iterrows():\n",
    "        cls = item[1].label if 'label' in df.columns else ''\n",
    "        print (f'narrative -> {item[1].narrative}')\n",
    "        print (f'clean text-> {item[1][col]} -> {cls}')\n",
    "        print('____________________________________________________________________')\n",
    "\n",
    "# our cleaning text returns slipped and tripped if keyword matches without the product information\n",
    "# so we add the product to the cleaned text if not present.\n",
    "def add_product_information(df_extracted_semantic, cls, add_cls=True):\n",
    "    for item in tqdm(df_extracted_semantic.iterrows(), total=df_extracted_semantic.shape[0]):\n",
    "        if item[1].text=='slipped and fell':\n",
    "            df_extracted_semantic.loc[item[0], 'text'] = df_extracted_semantic.iloc[item[0]].text + f' due to {df_extracted_semantic.iloc[item[0]].product_1.lower()}'\n",
    "        if item[1].text=='tripped and fell':\n",
    "            df_extracted_semantic.loc[item[0], 'text'] = f'tripped on {df_extracted_semantic.iloc[item[0]].product_1.lower()}'\n",
    "        if add_cls:\n",
    "            for a in cls:\n",
    "                if a in df_extracted_semantic.iloc[item[0]].narrative.lower() and a not in df_extracted_semantic.iloc[item[0]].text:\n",
    "                     df_extracted_semantic.loc[item[0], 'text'] = df_extracted_semantic.iloc[item[0]].text + f' while {a}' \n",
    "    return df_extracted_semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b7a8019-dd1c-4a48-ad40-3eb85f03279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 115128/115128 [01:11<00:00, 1603.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# we want a maximally clean text with only the verb that describes a precipitating event \n",
    "# for this particular analysis,  therfore we remove all else.\n",
    "stop_words = stop_words_base.copy()\n",
    "stop_words = add_body_part_to_stop_words(stop_words)\n",
    "stop_words = add_location_to_stop_words(stop_words)\n",
    "stop_words = add_product_to_stop_words(stop_words)\n",
    "\n",
    "# Through some iterative trials we found these to be occuring, which we want to remove\n",
    "fww = ['lost', 'left', 'ing', 'found', 'missed', 'gave', 'patient', \n",
    "       'evening', 'morning', 'noted', 'nursing', 'house']\n",
    "# for this analysis we also want only the verb that describes an event\n",
    "cleaner = lambda x: clean_narrative_semantics(x, stopwords=stop_words, filter_vb=['VBN', 'VBD', 'VBG'], filter_words=fww)\n",
    "\n",
    "df['text_clean'] = df.narrative.progress_apply(cleaner)\n",
    "# for this particular analysis these words are also unnecessary\n",
    "df['text_clean'] = df.text_clean.apply(lambda x: x.replace('fell','').replace('fall','').replace('and', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb5aa27-b02e-4cae-875b-41a17e9c435a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115128, 1994)\n",
      " silhouette_score 0.550832822319858\n",
      "Top terms per cluster:\n",
      "Cluster 0: tripped\n",
      " yestwithwalking\n",
      " headknocking\n",
      "Cluster 1: trying\n",
      " striking\n",
      " sitting\n",
      "Cluster 2: slipped\n",
      " yestwithwalking\n",
      " grown\n",
      "Cluster 3: unwitnessed\n",
      " suffered\n",
      " striking\n",
      "Cluster 4: hitting\n",
      " feeling\n",
      " getting\n",
      "Cluster 5: getting\n",
      " striking\n",
      " ling\n",
      "Cluster 6: mentioned\n",
      " not\n",
      " yestwithwalking\n",
      "Cluster 7: sided\n",
      " trying\n",
      " developed\n",
      "Cluster 8: ing\n",
      " injuring\n",
      " striking\n",
      "Cluster 9: walking\n",
      " striking\n",
      " causing\n"
     ]
    }
   ],
   "source": [
    "# we now cluster the verbs (num_cluster=10  default) using countvectorizer to get a grasp of the centroids and hence\n",
    "# commonly used verb to describe different precipitating event\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 10 \n",
    "count_vect = CountVectorizer()\n",
    "bow = count_vect.fit_transform(df['text_clean'].values)\n",
    "print (bow.shape)\n",
    "# to understand what kind of words generated as columns by BOW\n",
    "try:\n",
    "    terms = count_vect.get_feature_names()\n",
    "except:\n",
    "    terms = count_vect.get_feature_names_out()\n",
    "\n",
    "# using all processes jobs=-1 and k means++ for starting initilization advantage\n",
    "# n_jobs not working in older sklearn but could be reset later for faster performance\n",
    "model = KMeans(n_clusters = n_clusters ,init='k-means++', random_state=99) \n",
    "model.fit(bow)\n",
    "labels = model.labels_\n",
    "cluster_center=model.cluster_centers_\n",
    "score = silhouette_score(bow, labels, metric='euclidean')\n",
    "print (f' silhouette_score {score}')\n",
    "\n",
    "#Refrence credit - to find the top 10 features of cluster centriod\n",
    "#https://stackoverflow.com/questions/47452119/kmean-clustering-top-terms-in-cluster\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :3]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c91f961-e7d6-46af-9360-32cfb811baae",
   "metadata": {},
   "source": [
    "As expected 'slipped' and 'tripped' are the two cluster centroids; along with other verb that can be used in constructing our query for semantic search . The silhouette score of 0.56 means the clusters are cohesive and seperable.\n",
    "\n",
    "Lets also see how relevant these clustering of verbs describing the events are in a supervised machine learning setting. We are given diagnosis and body_part involved as categorical variables; by applying a simple randomforest classifier to predict these variables given other variables in the dataset plus the newly engineered cluster lables as additional variable , we can know variable importance.\n",
    "\n",
    "Here we will apply randomforest classifier with: \\\n",
    "  class_weights set to 'balanced' \\\n",
    "  scoring metric to 'precision score'\n",
    "as body_part and diagnosis are imbalanced. We will evaluate the importance using permutation importance. We will also not use 'diagnosis' or 'disposition' in predicting 'body_part' as this may lead to <span style='color:green'> leakage </span>. i.e disposition comes after diagnosis and diagnosis comes after knowing body_part.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2500a4d-789d-4244-a240-2c4f40783d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'head': 41138, 'lower trunk': 17663, 'face': 11649, 'upper trunk': 9625, 'shoulder': 4403, 'knee': 4199, 'upper leg': 3446, 'upper arm': 3059, 'wrist': 2899, 'lower arm': 2703, 'lower leg': 2662, 'ankle': 2110, 'elbow': 2108, 'neck': 1864, 'hand': 1230, 'foot': 1040, 'finger': 891, 'all parts body': 673, 'mouth': 587, 'toe': 360, 'ear': 339, 'not stated/unk': 294, 'eyeball': 116, 'pubic region': 63, 'internal': 7}\n",
      "\n",
      "{'fracture': 37125, 'internal injury': 30843, 'contusions, abr.': 19483, 'laceration': 12417, 'strain, sprain': 3951, 'hematoma': 3671, 'other': 2522, 'avulsion': 1845, 'dislocation': 1336, 'concussion': 937, 'poisoning': 350, 'nerve damage': 230, 'hemorrhage': 153, 'dental injury': 84, 'burns, thermal': 54, 'puncture': 39, 'burn, scald': 19, 'amputation': 19, 'foreign body': 16, 'derma/conjunct': 10, 'crushing': 8, 'aspiration': 7, 'anoxia': 3, 'burn, chemical': 3, 'burn, not spec.': 2, 'electric shock': 1}\n"
     ]
    }
   ],
   "source": [
    "print(df['body_part'].value_counts().to_dict())\n",
    "print()\n",
    "print (df['diagnosis'].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c47e1085-7358-4311-ae3f-dec1ef5b2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, make_scorer, precision_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "scorer = make_scorer(precision_score, average='micro')\n",
    "\n",
    "def plot_permutation_importance(clf, X, y, ax):\n",
    "    \n",
    "    result = permutation_importance(clf, X, y, n_repeats=10, random_state=42, n_jobs=-1, scoring=scorer)\n",
    "    perm_sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "    ax.boxplot(\n",
    "        result.importances[perm_sorted_idx].T,\n",
    "        vert=False,\n",
    "        labels=X.columns[perm_sorted_idx],\n",
    "    )\n",
    "    ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "def make_data_for_classification(df, use_cols, y_col):\n",
    "    X = df[use_cols]\n",
    "    y = df[y_col]\n",
    "    y_map = {i: j for i, j in zip(np.unique(y), range(0, len(y)))}\n",
    "    y = pd.Series([y_map[v] for v in y.values])\n",
    "    return X, y, y_map\n",
    "\n",
    "\n",
    "def make_importance_plots(y_col, verb_cluster_labels, thres_counts):\n",
    "    df_cat = pd.read_csv(primary_path)\n",
    "    df_cat['verb_cluster_labels'] = verb_cluster_labels\n",
    "    vcounts = df_cat[y_col].value_counts().to_dict()\n",
    "    vcounts_use = [k for k, v in vcounts.items() if v>thres_counts]\n",
    "    df_cat = df_cat[df_cat[y_col].isin(vcounts_use)].reset_index(drop=True)\n",
    "    print (f'num samples removed-> {df.shape[0]-df_cat.shape[0]}')\n",
    "    #print (df_cat[y].unique())\n",
    "\n",
    "    use_cols = ['sex', 'race', 'location', 'fire_involvement', 'alcohol', 'drug', 'product_1', 'body_part']\n",
    "    if y_col in use_cols:\n",
    "        use_cols.remove(y_col)\n",
    "    use_cols.extend(['verb_cluster_labels'])\n",
    "    X, y, y_map = make_data_for_classification(df_cat, use_cols=use_cols, y_col=y_col)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    clf = RandomForestClassifier(10, class_weight='balanced', n_jobs =-1, random_state=13)\n",
    "    use_cols.remove('verb_cluster_labels')\n",
    "    print(f'cross_val_score without the cluster labels= ', np.mean(cross_val_score(clf, X[use_cols], y, cv=5, \n",
    "                                                                                   scoring=scorer)))\n",
    "    use_cols.extend(['verb_cluster_labels'])\n",
    "    print(f'cross_val_score with the cluster labels= ', np.mean(cross_val_score(clf, X[use_cols], y, cv=5, \n",
    "                                                                                scoring=scorer)))\n",
    "    clf.fit(X_train, y_train )\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    plot_permutation_importance(clf, X_test, y_test, ax)\n",
    "    ax.set_title(f\"Permutation Importances on selected features for predicting {y_col}\")\n",
    "    ax.set_xlabel(\"Decrease in precision_score score\")\n",
    "    ax.figure.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36c3900d-e4fa-450e-b16e-c3e6a1d97559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del count_vect, bow, model\n",
    "gc.collect()\n",
    "#make_importance_plots('diagnosis', labels, thres_counts=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8611c8fc-7d58-42a7-a1f8-5a875238eff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples removed-> 3330\n",
      "cross_val_score without the cluster labels=  0.08797099629952952\n",
      "cross_val_score with the cluster labels=  0.10374059670776462\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_importance_plots('body_part', labels, thres_counts=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacaebbf-5197-4e05-98b9-4ead9c21eb29",
   "metadata": {},
   "source": [
    "From the cross validation score and permuation importance( we avoid impurity based feature importance as product_1 has high cardinality), we can gather that the verb describing the action clusterd into 10 groups has an impact on the body part being affected. We use precision score (average=micro) for scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bb3fe1-8d21-4c5f-82fc-ce6c6627c9c0",
   "metadata": {},
   "source": [
    "Now we will evaluate semantic search using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "953ce8ce-1c24-4e13-aec2-485f79d57be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FAISS vector store database with the host provided embeddings of primary narrative\n",
    "def load_embeddings_to_faiss(path, gpu=False):\n",
    "    data = pd.read_parquet(path)\n",
    "    embeds_narrative = np.vstack(data['embedding'])\n",
    "    n_dimensions = embeds_narrative.shape[1]\n",
    "    # We will create an index of type FlatL2, there are many kinds of indexes, you can look at it in their repo.\n",
    "    fastIndex_cpu = faiss.IndexFlatL2(n_dimensions)\n",
    "    # rane search does not work with gpu\n",
    "    if gpu:\n",
    "        res = faiss.StandardGpuResources()  # use a single GPU\n",
    "        fastIndex = faiss.index_cpu_to_gpu(res, 0, fastIndex_cpu)\n",
    "    else:\n",
    "        fastIndex = fastIndex_cpu\n",
    "    # Add the embedding vector to faiss index, it should be of dtype 'float32'\n",
    "    fastIndex.add(embeds_narrative.astype('float32')) \n",
    "    return fastIndex\n",
    "\n",
    "# get the embeddings of query from openai\n",
    "def get_query_embeds(groups_activity, file_name=''):\n",
    "   \n",
    "    activities = groups_activity.keys()\n",
    "    q_template = groups_activity.values()\n",
    "    if not os.path.isfile(file_name):\n",
    "        print ('Getting embeddings from OpenAI')\n",
    "        embedding_cls = [OpenAIEmbeddingsWithKey.embed_query(q) for q in q_template]\n",
    "        embedding_cls = np.asarray(embedding_cls).astype('float32')\n",
    "        print (embedding_cls.shape)\n",
    "        embeds = {k:v for k, v in zip(activities, embedding_cls)}\n",
    "        embeds['template'] = groups_activity\n",
    "        if file_name!='':\n",
    "            pickle.dump(embeds, open(file_name, 'wb')) \n",
    "    else:\n",
    "        print ('Loading saved..')\n",
    "        embeds = pickle.load(open(file_name, 'rb'))\n",
    "    return embeds\n",
    "\n",
    "# perform range search given query embedings and some threshold value \n",
    "def extract_query_result(embeds, thres=0.44):\n",
    "    df = load_primary(primary_path)\n",
    "    activities = embeds.keys()\n",
    "    for q in embeds.keys():\n",
    "        df[q] = [1]*df.shape[0]\n",
    "    for query_text, embedding_q in embeds.items():\n",
    "        result = fastIndex.range_search(embedding_q.reshape(1, -1).astype('float32'), thres)\n",
    "        df.loc[result[2], query_text]=result[1]\n",
    "\n",
    "    df_extracted_semantic = df[df[activities].sum(axis=1)!=len(activities)]\n",
    "    print (df_extracted_semantic.shape, df.shape) \n",
    "    return df_extracted_semantic\n",
    "\n",
    "# https://opentsne.readthedocs.io/en/latest/examples/index.html\n",
    "# From community code:  https://www.drivendata.org/competitions/217/cdc-fall-narratives/community-code/50/\n",
    "def reduce_dimension(x, nb_samples = 20000):\n",
    "    np.random.seed(13)\n",
    "    indices = np.random.permutation(list(range(x.shape[0])))\n",
    "    reverse = np.argsort(indices)\n",
    "\n",
    "    x_sample, x_rest = x[indices[:nb_samples]], x[indices[nb_samples:]]\n",
    "\n",
    "    sample_affinities = openTSNE.affinity.PerplexityBasedNN(\n",
    "        x_sample,\n",
    "        perplexity=500,\n",
    "        n_jobs=-1,\n",
    "        random_state=0,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    sample_init = openTSNE.initialization.pca(x_sample, random_state=42)\n",
    "    sample_embedding = openTSNE.TSNE(n_jobs=-1).fit(affinities=sample_affinities, \n",
    "                                                    initialization=sample_init)\n",
    "    rest_init = sample_embedding.prepare_partial(x_rest, k=1, perplexity=1/3)\n",
    "    init_full = np.vstack((sample_embedding, rest_init))[reverse]\n",
    "\n",
    "    embeddings2 = init_full / (np.std(init_full[:, 0]) * 10000)\n",
    "    return embeddings2\n",
    "\n",
    "\n",
    "# get sentence embeddings using sentence_transformers\n",
    "def get_embeddings(sentences, pretrained=\"paraphrase-multilingual-mpnet-base-v2\"):\n",
    "    model = SentenceTransformer(pretrained)\n",
    "    embeddings = model.encode(sentences, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# silhouette score and calinski_harabasz score as evaluation metrics of cluster results\n",
    "def usup_cluster_score(embedings, labels):\n",
    "    print (embedings.shape, labels.shape)\n",
    "    ss = silhouette_score(embedings, labels)\n",
    "    chs = calinski_harabasz_score(embedings, labels)\n",
    "    #dbs  = davies_bouldin_score(embedings, labels)\n",
    "    print (f'silhouette_score = {ss}')\n",
    "    print (f'calinski_harabasz_score = {chs}')\n",
    "    #print (f'davies_bouldin_score = {dbs}')\n",
    "    \n",
    "# convenience function that puts it all together, i.e \n",
    "#     get query embedings\n",
    "#     do FAISS range search, \n",
    "#     clean narrative, label if multiple queries\n",
    "#     get embeddings of the cleaned text, \n",
    "#     reduces the dimension then evalute using sillhoute and calinski_harabasz score\n",
    "\n",
    "def get_query_results(kv, remove_to_clean =['body_part', 'location'] , thres=0.37, file_name='', add_cls=True):\n",
    "    cls = list(kv.keys())\n",
    "    q_template = [v for v in kv.values()]\n",
    "    for i, v in enumerate(q_template):\n",
    "        print (i, v)\n",
    "    embeds = get_query_embeds(kv, file_name=file_name)\n",
    "    print (embeds['template'])\n",
    "    embeds.pop('template')\n",
    "    df_extracted_semantic = extract_query_result(embeds, thres=thres).reset_index()\n",
    "    df_extracted_semantic[\"label\"] = [cls[ix] for ix in np.argmin(df_extracted_semantic[cls].values, axis=1)]\n",
    "    print (df_extracted_semantic.shape)\n",
    "    print (df_extracted_semantic.label.value_counts()) \n",
    "    stop_words = stop_words_base.copy()\n",
    "\n",
    "    print(\"cleaning words\")\n",
    "    # remove already existing values from narrative\n",
    "    if 'body_part' in remove_to_clean:\n",
    "        stop_words = add_body_part_to_stop_words(stop_words)\n",
    "    if 'location' in remove_to_clean:\n",
    "        stop_words = add_location_to_stop_words(stop_words)\n",
    "    if 'product' in remove_to_clean:\n",
    "        stop_words = add_product_to_stop_words(stop_words)\n",
    "\n",
    "    print(\"clean narrative semantics\")\n",
    "    cleaner = lambda x: clean_narrative_semantics(x, stopwords=stop_words, filter_vb=None, \n",
    "                                                  filter_words=['nursing', 'house'])\n",
    "\n",
    "    df_extracted_semantic['text'] = df_extracted_semantic.narrative.progress_apply(cleaner)\n",
    "    df_extracted_semantic['text'] = df_extracted_semantic.text.apply(lambda x: x.replace('patient', ''))\n",
    "\n",
    "    if 'product' not in remove_to_clean:\n",
    "        df_extracted_semantic = add_product_information(df_extracted_semantic, cls, add_cls = add_cls) \n",
    "    if len(kv)>1:          \n",
    "        print(\"getting embeddings\")\n",
    "        clean_embeddings = get_embeddings(list(df_extracted_semantic[\"text\"]))\n",
    "        print(\"reducing dimensions\")\n",
    "        embeddings2 = reduce_dimension(clean_embeddings)\n",
    "        df_extracted_semantic[\"emb0\"] = embeddings2[:,0]\n",
    "        df_extracted_semantic[\"emb1\"] = embeddings2[:,1]\n",
    "        print(\"running usup cluster score\")\n",
    "        usup_cluster_score(embeddings2, df_extracted_semantic.label.values)\n",
    "    return df_extracted_semantic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d6fa250-dd96-40a2-b1a9-366a9db3c993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x7fb90a700510> >"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastIndex = load_embeddings_to_faiss(embedding_path)\n",
    "fastIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15b120b7-4fcf-479a-99b2-d1292f748649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAIEmbeddingsWithKey= OpenAIEmbeddings(openai_api_key=openai_key_uk, model_kwargs={'temperatue' : 0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "451819d9-3d80-4e44-b0e0-7467edc8a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE\n",
    "%load_ext dotenv\n",
    "%dotenv ../../../competition-cdc-unsupervised/.env -o\n",
    "\n",
    "OpenAIEmbeddingsWithKey = OpenAIEmbeddings(\n",
    "    deployment=\"text-embedding-ada-002\",\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    openai_api_base=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    model_kwargs={'temperatue' : 0.0}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce6908f",
   "metadata": {},
   "source": [
    "First let us get a sense of how relevant the returned results are through a simple search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5072876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "narrative -> 79 YOF TRIPPED OVER AN EXTENSION CORD. DX: CLOSED HEAD INJURY.\n",
      "clean text-> internal injury -> \n",
      "____________________________________________________________________\n",
      "narrative -> 67YOF TRIPPED OVER AN EXTENSION CORD AND LANDED ONTO A LADDER THAT WAS ON THE GROUND SUSTAINED A RIB FX\n",
      "clean text-> fracture -> \n",
      "____________________________________________________________________\n",
      "narrative -> 81YF WAS PLUGGING A CORD WHEN TRIPPED&FELL, DX: KNEE CONTUSION\n",
      "clean text-> contusions, abr. -> \n",
      "____________________________________________________________________\n",
      "narrative -> 72YOF TRIPPED AND FELL ON AN ELECTRIC CORD--DX:CONTUSION HEAD+KNEE PAIN\n",
      "clean text-> contusions, abr. -> \n",
      "____________________________________________________________________\n",
      "narrative -> 70YOM TRIPEPD OVER AN EXTENSION CORD AT HOME AND FELL ONTO KNEE SUSTAINED A CONTUSION TO KNEE\n",
      "clean text-> contusions, abr. -> \n",
      "____________________________________________________________________\n",
      "narrative -> 71 YOF GROUND LEVEL FALL TRIPPED OVER EXTENSION CORD DX SCALP LACERATION\n",
      "clean text-> laceration -> \n",
      "____________________________________________________________________\n",
      "narrative -> 73YOM TRIPPED OVER AN EXTENSION CORD ON HIS LANI. DX: CLOSED HEAD INJURY\n",
      "clean text-> internal injury -> \n",
      "____________________________________________________________________\n",
      "narrative -> 87YOF WALKING AT HOME, TRIPPED OVER EXTENSION CORD. FELL HITTING HEAD DX: CLOSED HEAD INJURY\n",
      "clean text-> internal injury -> \n",
      "____________________________________________________________________\n",
      "narrative -> 72YF TRIPPED OVER A CORD&FELL TO THE FLOOR IN LR>>KNEE CONTS\n",
      "clean text-> contusions, abr. -> \n",
      "____________________________________________________________________\n",
      "narrative -> 68 YOF TRIPPED ON ELECTRIC EXTENSION CORD DX RIB FX\n",
      "clean text-> fracture -> \n",
      "____________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "qe = OpenAIEmbeddingsWithKey.embed_query('tripped on cord')\n",
    "D, I = fastIndex.search(np.asarray([qe]).astype('float32'), 10)     # actual search\n",
    "show_samples(df.iloc[I.flatten()], col='diagnosis', n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e78a01",
   "metadata": {},
   "source": [
    "As we can see above our setup returns relevant result. We will though, use 'range search' instead as this operation returns all index calculated from distance metric between query and value embeddings and a specified threshold enabling us to draw conclusions about the distribution.\n",
    "\n",
    "We will start with fall when a <span style='color:brown'>Walker is involved and compare it with fall in Stairs</span>. Walker is not in product mapping specified in coding manual so without searching for it in the narratives, further study on it would not have been possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c79f26",
   "metadata": {},
   "source": [
    "At this point we would like to mention that, as shown in introductary figure of broadly categorizing activities, that some context is good for forming queries but too much may not be useful, given that our narrativea are short with repetative words for location, body_part, diagnosis etc. Including too much context may lead to too many matches hence loosing the specificity desired. Of course you can counter this with lowering the threshold, in which case too few samples maybe returned. This can be\n",
    "best seen by forming your own queries and inspecting the result. We believe in practice, forming a query with action and 1 or 2 context is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ac072-ef6b-4a15-9e2f-1100ee5f1bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 using walker\n",
      "1 going down stairs\n",
      "Loading saved..\n",
      "{'walker': 'using walker', 'stairs': 'going down stairs'}\n",
      "(6272, 24) (115128, 24)\n",
      "(6272, 26)\n",
      "label\n",
      "stairs    4898\n",
      "walker    1374\n",
      "Name: count, dtype: int64\n",
      "cleaning words\n",
      "clean narrative semantics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 6272/6272 [00:01<00:00, 4090.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 6272/6272 [00:01<00:00, 5989.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting embeddings\n"
     ]
    }
   ],
   "source": [
    "# Here we setup two queries for camparison where key is just a label and value is the actual query to be searched\n",
    "groups_walker_stair = {'walker' : 'using walker', 'stairs': 'going down stairs'}\n",
    "df_walker_ex = get_query_results(groups_walker_stair, remove_to_clean = ['body_part','location'], \n",
    "                                 thres=0.37, file_name=DATA_DIR / 'interim/g_embeddings_walker_stairs.pkl')\n",
    "\n",
    "df_walker_ex = df_walker_ex[df_walker_ex.text.apply(lambda x: not 'not mentioned' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68d148c-f92e-4594-a4f8-335edb8ff538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a few random samples\n",
    "show_samples(df_walker_ex, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b62a54-4163-4b2d-bcf1-79d88f90172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", rc={'figure.figsize':(8, 6)})\n",
    "sns.scatterplot(data=df_walker_ex, x='emb0', y='emb1', hue='label').set(\n",
    "    title='Compare cluster between fall while using walker and going down stairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec6d458-2360-44fc-a6e3-598bfff4611b",
   "metadata": {},
   "source": [
    "Silhouette_score suggests good cohesion of cluster and intra cluster seperability. The clean text is concise and mentions the action and product combined to cause the fall. Now we look at how they are distributed according to age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be42be67-a713-4967-9f45-f835475eb420",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = sns.histplot(df_walker_ex, x='age',  kde=True, discrete=True,\n",
    "                 stat = 'proportion', hue='label', multiple='dodge').set(\n",
    "    title='Histogram of fall for walker use and going down stairs')\n",
    "h = plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b765dc2-4d2f-4616-8513-ed4831caf233",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Unlike the gaussian distribution with peak at age 85 for fall using walker,  fall going down steps is \n",
    "declining sharply from age 76 (long-tailed), as age progresses. This could perhaps be explained from the fact that as age \n",
    "progresses more people will start using walker while they limit the use of stairs</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f607c",
   "metadata": {},
   "source": [
    "An alternative to FAISS semantic search is to pass the narrative through OpenAI chatgpt3.5 turbo. \n",
    "We evaluate this method and compare it to ours before moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc9786-1da9-4169-92b7-190ca1b015db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = openai_key_uk\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f0170d-de5a-4958-9119-0e8084c2eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is a response file already obtained for loading\n",
    "# set to false ensuring you have a working openai key\n",
    "load_precomputed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358b793-1c01-49cb-b9c9-f3f44c4c3bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "RESPONSE_DIR = DATA_DIR / 'interim/response/'\n",
    "os.makedirs(RESPONSE_DIR, exist_ok=True)\n",
    "# control the numbers of items to send via start_index, end_index and num_items_per_request\n",
    "# currently for demonstration we break after one iteration and load n samples already obtained\n",
    "# remove the break if you would like to gather more of the response from chatgpt.\n",
    "start_index = 0 \n",
    "end_index = df.shape[0]\n",
    "num_items_per_request = 20 # 200 max\n",
    "response_openai = {}\n",
    "if load_precomputed is True:\n",
    "    print ('Loading precomputed ...')\n",
    "    response = json.load(open(RESPONSE_DIR / f'response_{str(0)}.json', 'r'))\n",
    "    response_openai[start_index]=response\n",
    "else:\n",
    "    for i in tqdm(range(start_index, end_index, num_items_per_request)):\n",
    "        item = json.dumps(df.iloc[start_index:start_index+num_items_per_request].narrative.values.tolist())\n",
    "        prompt = f\"\"\" What was the subject doing before the fall in each text inside double quotation\n",
    "        in the text delimited by triple backticks.\n",
    "        text: ```{item}```..\n",
    "            \"\"\"\n",
    "        try:\n",
    "            response = get_completion(prompt)\n",
    "            json.dump(response, open(RESPONSE_DIR / f'response_{str(start_index)}.json', 'w'))\n",
    "            response_openai[start_index]=response\n",
    "            start_index = start_index+num_items_per_request\n",
    "        except:\n",
    "            print ('Exception....sleeping..')\n",
    "            time.sleep(60)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd5bc4-825b-4f4f-9d30-6ebae85450aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# lets look at the response returned by openai chatgpt 3.5 turbo \n",
    "# the reurned results are cleaned removing bullet list numbering        \n",
    "doing_before = []\n",
    "g = glob.glob(RESPONSE_DIR / '*.json')\n",
    "for gi in tqdm(g):\n",
    "    res = json.load(open(gi))\n",
    "    response = res.split('\\n')\n",
    "    response = [item for item in response if item!='']\n",
    "    for item in response[1::]:\n",
    "        item = item if ' - ' not in item else item.split(' - ')[1]\n",
    "        r = \" \".join(re.split(r'\\s*(?:\\d+\\.|[A-Za-z]+\\))\\s*', item)).strip()\n",
    "        r = r.replace('The activity before the fall was ','')\n",
    "        if '\"' in r:\n",
    "            continue\n",
    "        doing_before.append(r)\n",
    "doing_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d43bf8-83f6-40e4-aecf-28458286d43f",
   "metadata": {},
   "source": [
    "We clearly see a very consise activity description returned from openai with the extra irrelevant information stripped out. While convinient the response takes time (we additionally send only 20 narratives at a time to be within token limits). Executing all the narratives will need additional constraint to be set for rate limit. For the 115128 primary narratives, this will take a long time.\n",
    "\n",
    "We feel simple semantic search as described above is adequate and significantly faster, we will however analyse further ~5000 samples using this approach to demonstrate an alternative. These were extracted beforehand and simply loaded here for demonstration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d6cd1-729c-4bfc-af5e-ba15b67f86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_openai_activities = json.load(open(DATA_DIR / 'interim/openai_precipitating.json'))\n",
    "openai_activities = []\n",
    "for item in tmp_openai_activities:\n",
    "    item = item.replace('.','').replace(',',' ')\n",
    "    new_item = []\n",
    "    for w in item.split(' '):\n",
    "        if w not in ['fell', 'fall', 'Fell', 'Fall']:\n",
    "            # we removes stop words , body part, location for cmarision to faiss results as above\n",
    "            if w not in stop_words_base:\n",
    "                if w not in body_part:\n",
    "                    if w not in location:\n",
    "                        new_item.append(w)\n",
    "    openai_activities.append(' '.join(new_item).lower())\n",
    "    #openai_activities.append(item)\n",
    "print (len(openai_activities))\n",
    "openai_activities = [item for item in openai_activities if item not in ['no specific activity mentioned', \n",
    "                     'not specified', 'unknown']]\n",
    "openai_activities = [item for item in openai_activities if item!='']\n",
    "print (len(openai_activities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc8447-2bd0-4f05-8525-4dd2a1e25b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we obtain the reduced embeddings for clustering\n",
    "openai_embeddings = get_embeddings(openai_activities)\n",
    "reduced_openai_embeddings = reduce_dimension(openai_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbca49e-9be9-4a68-b8e9-49eebc6ed30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using kmeans++ we evalute the clusters using silhouette_score\n",
    "model_openai = KMeans(n_clusters = 7, init='k-means++',random_state=99) # n_jobs = -1\n",
    "model_openai.fit(reduced_openai_embeddings)\n",
    "\n",
    "dfo = pd.DataFrame(reduced_openai_embeddings, columns=['emb0', 'emb1'])\n",
    "dfo['label'] = model_openai.labels_\n",
    "\n",
    "score = silhouette_score(reduced_openai_embeddings, dfo.label, metric='euclidean')\n",
    "print (f' silhouette_score {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d8767-22b0-465a-91a5-8ff542a17e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity    \n",
    "# lets see exactly how each centroid maps to the text\n",
    "center_ = {}\n",
    "for i, cc in enumerate(model_openai.cluster_centers_):\n",
    "    ix = np.argmin(euclidean_distances([cc], dfo[['emb0', 'emb1']].values))\n",
    "    center_[i] = openai_activities[ix]\n",
    "\n",
    "for k, v in center_.items():\n",
    "    print (k,' --> ' ,v)\n",
    "dfo['label_map']  = dfo.label.map(center_)\n",
    "print(center_)\n",
    "\n",
    "sns.set(style=\"whitegrid\", rc={'figure.figsize':(16, 8)})\n",
    "sns.scatterplot(data=dfo, x='emb0', y='emb1', hue='label_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa25cc1-70b0-4ef8-b5f2-78b98cff7e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the full embedings for cosine similarity \n",
    "walker_embeddings = get_embeddings(df_walker_ex[df_walker_ex.label=='walker'].text.values.tolist())\n",
    "stair_embeddings = get_embeddings(df_walker_ex[df_walker_ex.label=='stairs'].text.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893cfcde-9567-4e48-9844-c74454d282cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare cosine similarities between embeddings of openai chatgpt results and our embeddings of cleaned text\n",
    "\n",
    "dws = df_walker_ex[df_walker_ex.label=='stairs']\n",
    "for u in list(center_.keys()):\n",
    "    #dus = dfo[dfo.label==u][['emb0', 'emb1']]\n",
    "    #sim = cosine_similarity(dus[['emb0', 'emb1']], dws[['emb0', 'emb1']]).mean()\n",
    "    sim_1 = cosine_similarity(openai_embeddings[dfo[dfo.label==u].index],walker_embeddings).mean()\n",
    "    sim_2 = cosine_similarity(openai_embeddings[dfo[dfo.label==u].index],stair_embeddings).mean()\n",
    "    print (f'{u}, centroid text ->{center_[u]}, sim (walker) {sim_1}, sim (stairs) {sim_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a967c62-e11d-4491-86d4-085119e066a3",
   "metadata": {},
   "source": [
    "From the text of cluster centroid we see the different prodcut combined with different actions constitute a precipitating event such as 'Trying to sit on chair' , 'Going to the bathroom' and 'Slipping on a wet floor'. These we can also extract simply using FAISS and cleaned narrative as shown above but much faster (just cpu). \n",
    "Here one should keep in mind that the text being comapred have only few words, i.e 'getting down chair' is compared with 'getting down stairs' where the only difference is the product, i.e chair or stairs, so there will be some similarity due to action of getting down, regardless of the product and hence some similarity will always exists. Above we see, for label 1 ('down flight of concrete steps'), cosine similarity is much closer to stairs than walker and similarly for 3 ('slipped ambulating walker'), cosine similarity for walker is more closer than for stairs.\n",
    "\n",
    "The value of a cleaned text is for presenting a concise representation of precipitating event. Its also better in calculating the embedding for cluster analysis. But it plays no part in analysing the distribution of the result returned from a query. So we kept the cleaning to a minimum and did not go into a much elaborate parsing that might have generated a better formed cleaned text. Aside if we were to use chatgpt, the returned text would have needed another embeddings calculation and loaded to FAISS for similarity search or clustering approach to study some desired distributions. This could have meant two passes using an LLM and inherent noise in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d00fae6-3dfa-4b87-8561-1f1a8ebfcaf1",
   "metadata": {},
   "source": [
    "<span style='color:brown'> Semantic search with product only </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d071c-d46c-458b-a5c2-afb33609ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_describe = df.product_1.describe() \n",
    "print (vc_describe)\n",
    "print ()\n",
    "vc_product = df.product_1.value_counts().head(6)\n",
    "print (vc_product)\n",
    "print ()\n",
    "top_appearance = vc_product.sum()/df.shape[0]*100\n",
    "floor_appearance = df[df.narrative.apply(lambda x: \"floor\" in x.lower())].shape[0]\n",
    "print (f'Num product {len(vc_product)} out of {df.product_1.unique().shape[0]} contributes \\\n",
    "to {top_appearance} % of samples')\n",
    "print (f'floor appearing in narrative {floor_appearance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bb249b-478a-408a-b09c-7ff8a18cb46b",
   "metadata": {},
   "source": [
    "We see from the analysis above that top 6 of the product are involved in 65% of the samples. Furthermore some of the products are similar, so we will group the items accordingly. We make 4 classes based on product\n",
    "description only. Items such as chairs and couch or bathroom and toilet are grouped together as shown below. We also skip floor as a seperate class as its frequency is relatively high (46753 samples), and examples such as \"Fell to the floor\" is uninformative in knowing the cause of the fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bfe51e-6209-4db3-88b2-712eb23790d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_product = {'chair': 'chairs couch stool',\n",
    "                   'bed': 'beds ',\n",
    "                   'steps': 'stairs steps ladder', \n",
    "                   'bath': 'bathtubs bathroom shower toilet'}\n",
    "thres = 0.43\n",
    "# In addition to the stop_words we remove body_part and location\n",
    "remove_to_clean =['body_part', 'location'] \n",
    "df_product = get_query_results(groups_product, remove_to_clean=remove_to_clean, \n",
    "                               thres=thres, file_name=DATA_DIR / 'interim/g_embeddings_product.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd48ed3-3ea8-486e-8531-726a62dafd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we clearly see highly cohesive cluster formations\n",
    "sns.set(style=\"whitegrid\", rc={'figure.figsize':(16, 8)})\n",
    "sns.scatterplot(data=df_product, x='emb0', y='emb1', hue='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94ca9e-22a7-4ab1-b4d8-521f9808d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_samples(df_product, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1300e-152a-4823-9c5c-50c04814c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets analyse how fall from stairs or steps differs from the rest\n",
    "h  = sns.histplot(df_product, multiple='dodge', stat=\"density\",\n",
    "           x='diagnosis', hue='label').set(title='Fall diagnosis due to fall involving top product')\n",
    "h = plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe66c9-1fb3-40b2-8fb0-0ca2fdc558bf",
   "metadata": {},
   "source": [
    "<span style='color:blue'> As expected fracture is almost twice as high as the count of the next highest diagnosis when fall from steps (height) occurs.\n",
    "While falling from bed causes internal injury the most. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7664cf9-a2c5-457d-862f-5b440f769aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h  = sns.histplot(df_product, multiple='dodge', stat=\"density\",\n",
    "           x='location', hue='label').set(title='Location of fall based on top product involved')\n",
    "h = plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea5897-dc68-4bde-a16e-665ad0032295",
   "metadata": {},
   "source": [
    "<span style='color:blue'>  In the above histplot we clearly and surprisingly see that in PUBLIC(nursing home) counts of falling from bed is very high.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab1bd2c-6cac-49b7-9f0f-caece5fe20de",
   "metadata": {},
   "source": [
    "Lets do <span style='color:brown'>slipped and tripped</span>, and see which body parts is affected by each and the final diagnosis. Similar to prodcut semantic search, while we could have done keyword search here due to them being mentioned explicitly as per coding guide, there are instances where it is implied or variations such as just slip or trip are used, so we do semantic search and analyse the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5825b478-4e2f-4465-bf92-7c03513b7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_slip_trip = {'slip': 'slipped',\n",
    "                   'trip': 'tripped'}\n",
    "thres = 0.38\n",
    "df_slip_trip = get_query_results(groups_slip_trip, remove_to_clean = ['body_part','location'], \n",
    "                                 thres=0.37, file_name=DATA_DIR / 'interim/embeddings_slip_trip.pkl', add_cls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77968c1c-cf5d-424b-a218-15bcdd247b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", rc={'figure.figsize':(16, 8)})\n",
    "sns.scatterplot(data=df_slip_trip, x='emb0', y='emb1', hue='label').set(\n",
    "    title='Compare cluster between fall due to slip or trip')\n",
    "show_samples(df_slip_trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e73a05-08e0-4407-8b59-c386aa153df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df_slip_trip.product_1.value_counts().head(8))\n",
    "print()\n",
    "print ('samples in top 8 ->', df_slip_trip.product_1.value_counts().head(8).sum()/df_slip_trip.shape[0]*100, '%')\n",
    "df_slip = df_slip_trip[df_slip_trip.label=='slip']\n",
    "df_trip = df_slip_trip[df_slip_trip.label=='trip']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b69f00",
   "metadata": {},
   "source": [
    "Above we see formation of island of highly cohesive cluster which can be attributed to 'slipped in floor'  or\n",
    "'tripped in stairs' where floor and stairs are product involved in high fall incident count. But there are also scaterring of\n",
    "slipped and tripped events which can be attributed to them occuring in combination with other less frequently occuring product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb10e120-4547-4827-8a34-9db06870851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_to_consider = list(set(np.concatenate([df_slip.product_1.value_counts().head(8).index, \n",
    "                                      df_trip.product_1.value_counts().head(8).index])))\n",
    "h  = sns.histplot(df_slip_trip[df_slip_trip.product_1.isin(prod_to_consider)], \n",
    "           x='product_1', hue='label', stat='percent', multiple='dodge').set(title='Cause of slip or trip due to product')\n",
    "h = plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b338efa7-bb72-4b6e-9186-4297dac9182d",
   "metadata": {},
   "source": [
    "Slipping or Tripping in floor are almost equally likely.\\\n",
    "Tripping in rugs or carpet however far exceeds slipping .\\\n",
    "Slipping in bathtubs or shower (wet surface) is far more predominant as expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ae9f67-481e-404b-800b-7ee1b0ce4d95",
   "metadata": {},
   "source": [
    "Test hypothesis:\n",
    "1. Surface specially in Street are more slippery in winter months causing far more slip events?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9705ea9-7bbe-4336-bbb6-b5f147a5fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slip['treatment_date'] = pd.to_datetime(df_slip['treatment_date'])\n",
    "df_slip['month'] = df_slip.treatment_date.apply(lambda x: x.month)\n",
    "df_slip['year'] = df_slip.treatment_date.apply(lambda x: x.year)\n",
    "print (df_slip[df_slip.location=='STREET'].month.describe())\n",
    "h  = sns.histplot(df_slip[df_slip.location.isin(['SPORTS','STREET', 'SCHOOL','MOBILE'])], multiple='dodge', stat=\"probability\",\n",
    "           x='month', hue='location').set(title='Location specific fall by months')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770e6101-638f-4abf-a406-3d5aa4ad345d",
   "metadata": {},
   "source": [
    "<span style='color:blue'> We observe the increase in slip and fall in the street during winter months. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ae9328-8082-432a-9728-85f99c66c7ce",
   "metadata": {},
   "source": [
    "We can also construct graph(networkx) for data exploration and find fringe cases of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1f7e4-d644-46db-870c-01e9a98c509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the interactive graph using y-files and set scaling \n",
    "def make_y_files_graph(G, set_scaling=False):\n",
    "    w = GraphWidget(graph=G)\n",
    "    w.set_node_color_mapping('color')\n",
    "    w.set_graph_layout('organic')\n",
    "    # the sidebar is set to False but if you would like to interactively explore \n",
    "    # you can toggle it with sicon at bottom right\n",
    "    w.set_sidebar(False) \n",
    "    if set_scaling:\n",
    "        w.set_node_scale_factor_mapping('node_size')\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca3410-f1cc-4861-931a-281c13652ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_node = 4 # the scaling is just so that the graph renders in the alloted widget dimension for display\n",
    "G = nx.Graph()\n",
    "edges_body_diag =  []\n",
    "for item in tqdm(df_slip.iterrows(), total=df_slip.shape[0]):\n",
    "        edges_body_diag.append((item[1].body_part , item[1].diagnosis))\n",
    "        \n",
    "G.add_nodes_from(df_slip.body_part.unique(), color='blue')\n",
    "G.add_nodes_from(df_slip.diagnosis.unique(), color='red')\n",
    "G.add_edges_from(edges_body_diag)\n",
    "#We map the node_size based on degree\n",
    "for item  in nx.degree(G):\n",
    "    G.nodes[item[0]]['node_size']=item[1]/scale_node\n",
    "w = make_y_files_graph(G, set_scaling=True)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4102920-8591-42f1-add9-c5f7c291e6e6",
   "metadata": {},
   "source": [
    "We show a crop from the actual graph as the cell below (w.show()) needs to be run for graph rendering.\n",
    "\n",
    "Graph depicting relation of body to diagnosis, with node scale mapping  set by node degree\n",
    "![body_diag_graph](assets/slip_internal_injury.png)\n",
    "\n",
    "** Best visualized in fullscreen after rendering(run the cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e7845-93a0-4ee4-a30b-606a2d28b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101f855",
   "metadata": {},
   "source": [
    "As mentioned in introduction we test the hypothesis that 'Slipped' could lead to more back of the head injuries while 'Tripped' would cause more frontal injuries such as faces due to involutary forwad motion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad1b87-1ede-40e9-9f0a-d6ada9b771b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('For slip related event degree of internal injury=', G.degree('internal injury'))\n",
    "print ('which means theres are only 3 body part related to internal injury when slip occurs')\n",
    "slip_body_value_count = df_slip[df_slip.diagnosis=='internal injury'].body_part.value_counts(normalize=True).to_dict()\n",
    "print ()\n",
    "print (slip_body_value_count)\n",
    "s_head = slip_body_value_count['head']\n",
    "print (f'So injury to the head accounts for {s_head*100} % of internal injury')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418f977-d68d-403a-a094-78110e530eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('For tripped event')\n",
    "print (df_trip.body_part.value_counts(normalize=True).head(5))\n",
    "print ()\n",
    "print ('For slipped event')\n",
    "print (df_slip.body_part.value_counts(normalize=True).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ede80-04be-49e2-a9d8-515a06cb0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheak multiple occurences of body_part injuries\n",
    "def cheak_multiple_occurences(dfc, col1, col2,  part1, part2):\n",
    "    dtemp_1 = dfc[(dfc[col1].isin([part1, part2]))]\n",
    "    dtemp_2 = dtemp_1[(dtemp_1[col2].isin([part1, part2]))]\n",
    "    print (dtemp_2.shape[0]/dfc.shape[0]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69803823-9449-4c2c-87e9-7cdcad4ebde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('occurences of head and face injury when slip event happens')\n",
    "cheak_multiple_occurences(df_slip, 'body_part', 'body_part_2',  'head', 'face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeef5d7-fb2a-4125-9d9e-efd124d75f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('occurences of head and face injury when trip event happens')\n",
    "cheak_multiple_occurences(df_trip, 'body_part', 'body_part_2',  'head', 'face')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073e71d8-42df-4d4c-b52d-37bf4436abb1",
   "metadata": {},
   "source": [
    "So we conclude that in tripped event, injury to the face is twice as higher than when slipping occurs.\n",
    "But in both slipping and tripping head injury is the most a body_part is affected, \n",
    "We can not know which part of the head unless the narrative mentions this, though it \n",
    "would not be unreasonable to assume that a slip can cause injuries to the back."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1277238-99dc-4a1b-a50e-9b962d680f1b",
   "metadata": {},
   "source": [
    "Lets us explore fall caused due to <span style='color:brown'>dizzyness</span>, which can occur without involvement of external factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca99f8-b109-4fd6-903f-d45816177188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at what happens when falling due to dizzyness\n",
    "query_dizzy = {'dizzy': 'dizzy'}\n",
    "df_dizzy = get_query_results(query_dizzy, thres=0.37, file_name=DATA_DIR / 'interim/g_embeddings_dizzy.pkl')\n",
    "co_occurrence_matrix_dizzy  = pd.crosstab(df_dizzy['body_part'], df_dizzy['diagnosis'])\n",
    "sns.heatmap(co_occurrence_matrix_dizzy, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d1bc42-21b2-4d1b-8603-bc2f3f5c1a2c",
   "metadata": {},
   "source": [
    "<span style='color:blue'> Similar to slipping, fall due to dizzyness also involves high count of internal injury to the head.\n",
    "Doing semantic search with dizzy also captures  \"OFF BALANCE\" as dizzy, \n",
    "whereas simple keyword search would not have made this association. </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892a4dba-b515-4cad-8680-060403a9a36a",
   "metadata": {},
   "source": [
    "<span style='color:brown'>Excercise: </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6270ccfc-a53d-4032-8166-b5a9569d87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [v for v in mapping['product_1'].values() if 'activity' in v.lower()]\n",
    "print ('num activities:', len(activities))\n",
    "for i, v in enumerate(activities):\n",
    "    print (v)\n",
    "    if i==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaff47a-b482-47ec-879c-056bcc45f1d4",
   "metadata": {},
   "source": [
    "Although 81 exercise activities are explicitly given in product, we will do semantic search that encompasses them all (including dancing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7efed9-1be2-4579-99a9-a377f23056b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ex = {'excersize': 'exercising dancing'}\n",
    "df_exer = get_query_results(query_ex, thres=0.42, file_name=DATA_DIR / 'interim/g_embeddings_exercise.pkl')\n",
    "h = sns.histplot(df_exer, x='race',  stat = 'frequency', hue='sex', multiple='dodge').set(\n",
    "    title='Fall by race to exercising or dancing')\n",
    "h = plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac348df-cad0-4f34-9d00-b086a760a85b",
   "metadata": {},
   "source": [
    "<span style='color:blue'> White Female exercise and fall the most when race is given.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20616d4d-fe29-4b0e-a61a-38c113babd98",
   "metadata": {},
   "source": [
    "<span style='color:brown'> A semantic query that has body_part and product both as context could be done as follows: </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17622cb9-dcac-41f5-8bb9-cdc74f15e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here 'hit' and 'getting out' are the action, 'wall' and 'chair' are the product ,\n",
    "# 'head' and 'leg' are the body_part respectively\n",
    "groups_hit = {'wall' : 'hit wall head', 'getup': 'getting out chair ankle leg'}\n",
    "remove_to_clean = ['location'] # we only remove location and not the body part as it constitutes the query\n",
    "df_body = get_query_results(groups_hit, thres=0.37, remove_to_clean=remove_to_clean,\n",
    "                                          file_name='g_embeddings_hit.pkl')\n",
    "show_samples(df_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8db7a0-6bb2-4224-8a8a-257265511dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", rc={'figure.figsize':(6, 6)})\n",
    "sns.scatterplot(data=df_body, x='emb0', y='emb1', hue='label').set(title='Cluster comaprision between hitting wall \\\n",
    "with head and getting up hurting leg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a6c18-e2bc-4af9-a981-6813d503a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", rc={'figure.figsize':(16, 8)})\n",
    "\n",
    "g = sns.histplot(data=df_body,  x='diagnosis', stat = 'proportion', hue='label', multiple='dodge').set(\n",
    "    title='Diagnosis for hitting wall or hurting ankle when getting out of chair')\n",
    "g = plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd775efd-3bed-46cf-abae-7008cd85d97d",
   "metadata": {},
   "source": [
    "<span style='color:blue'> Hitting the wall with head results in internal injuries the most while fracture is more common when getting up from chair with leg injuries</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b939a-9c4f-4023-86c3-0da09cb436f6",
   "metadata": {},
   "source": [
    "<span style='color:brown'>We look at alcohol drug contribution to fall (on the full primary dataset) for each location </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b3dc78-7dd0-4eb2-9e10-1a5609703a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "edges_ad = []\n",
    "for item in df.iterrows():\n",
    "    if item[1].alcohol=='Yes':\n",
    "        edges_ad.append(('alcohol', item[1].location))\n",
    "    if item[1].drug=='Yes':\n",
    "        edges_ad.append(('drug', item[1].location))\n",
    "        \n",
    "G.add_nodes_from(['alcohol', 'drug'], color='red', node_size=1)\n",
    "G.add_nodes_from(df.location.unique().tolist(), color='yellow')\n",
    "\n",
    "G.add_edges_from(edges_ad)\n",
    "w = make_y_files_graph(G, set_scaling=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869972ad-df9b-49a7-94d8-e3fbb353e5be",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> Graph depicting alcohol and drug contribution in fall at given locations\n",
    "![alcohol_drug](assets/g_alcohol_drug.png) </span>\n",
    "\n",
    "** we show the graph as markdown image saved beforehand as for full interactive rendering of the graph the\n",
    "code below needs to be executed. For best visualization open in full screen (toggle in sidebar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb38e3c-5c10-4c10-aac1-df0677239ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1ad90-9047-4a7b-bf3f-7ac448361eb8",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We see that in FARM AND INDST drug and alcohol are never involved. \n",
    "Yet surprisingly drug being involved in school, and alcohol is not.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2109becd-9772-4c34-964d-749bbea02917",
   "metadata": {},
   "source": [
    "<span style='color:brown'> Sometimes multiple diagnosis are made, so lets look at those.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589a87b7-88b7-4636-a1b6-bf851e93d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_edges_multiple(df, nodes_columns=['diagnosis', 'diagnosis_2']):\n",
    "    edges_between_diag = []\n",
    "    for item in df[nodes_columns].iterrows():\n",
    "        item = item[1].values\n",
    "        if isinstance(item[0], str) and isinstance(item[1], str):\n",
    "            edges_between_diag.append(tuple(item))\n",
    "    nodes = df[nodes_columns[0]].unique()\n",
    "    return nodes  , edges_between_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4916de79-3b0d-408d-a73c-4077dc6039a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "n, e = get_nodes_edges_multiple(df, nodes_columns=['diagnosis', 'diagnosis_2'])\n",
    "G.add_nodes_from(n)\n",
    "G.add_edges_from(e)\n",
    "# We take each nodes centrality\n",
    "centrality_daig = nx.degree_centrality(G)\n",
    "h = sns.barplot(x=list(centrality_daig.keys()), y=list(centrality_daig.values())).set(title='Graph Centrality For Multiple Diagnosis')\n",
    "h = plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cff5f1-9fcd-4f15-a2df-4b3b636d38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'Num samples for fracture = {df.diagnosis.value_counts().fracture}')\n",
    "print (f'Num samples for poisoning = {df.diagnosis.value_counts().poisoning}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d6ef00-f0a1-45fb-bf31-5ff3814f6639",
   "metadata": {},
   "source": [
    "<span style='color:blue'> We see fracture to have the highest centrality , i.e more injuries can be present when we have fracture  and although there are relatively few samples for poisoning we also see a high centrality, which means it is often accompanied by other injuries</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db840835",
   "metadata": {},
   "source": [
    "We can create simple knowledge graphs to help us visualize the interaction between different columns easier. It allowed us\n",
    "to explore fringe cases far more effectively. For these demonstration we make the graph small by subsetting to categories with few samples such as: how are the other column details such as location, body part, sex etc interact when we pick only diagnosis assigned to nerve damage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1841a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_do = df[df.diagnosis=='poisoning']\n",
    "#df_do = df[df.disposition=='held for observation']\n",
    "\n",
    "df_do = df[df.diagnosis=='nerve damage']\n",
    "#print (df_do.shape)\n",
    "colors=['blue', 'red', 'green', 'yellow', 'purple']\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(list(mapping['location'].values()), color='yellow')\n",
    "G.add_nodes_from(df.body_part.unique().tolist(), color='red')\n",
    "G.add_nodes_from(list(mapping['race'].values()), color='green')\n",
    "G.add_nodes_from(list(mapping['sex'].values()), color='purple')\n",
    "\n",
    "edges_location_body =  []\n",
    "for item in tqdm(df_do.iterrows(), total=df_do.shape[0]):\n",
    "        edges_location_body.append((item[1].location , item[1].body_part))\n",
    "        \n",
    "edges_race_sex =  []\n",
    "for item in tqdm(df_do.iterrows(), total=df_do.shape[0]):\n",
    "        edges_race_sex.append((item[1].race , item[1].sex))\n",
    "\n",
    "edges_sex_location =  []\n",
    "for item in tqdm(df_do.iterrows(), total=df_do.shape[0]):\n",
    "        edges_sex_location.append((item[1].sex , item[1].location))\n",
    "\n",
    "G.add_edges_from(edges_location_body, relation='in')\n",
    "G.add_edges_from(edges_race_sex, relation='belongs')\n",
    "G.add_edges_from(edges_sex_location, relation='sex')\n",
    "\n",
    "# we use degree of a node to scale the nodes\n",
    "# here we clip the node size as there are isolated nodes whose degree are 0\n",
    "# which y-files had difficulty rendering \n",
    "for item  in nx.degree(G):\n",
    "    print (item)\n",
    "    G.nodes[item[0]]['node_size']=np.clip(item[1]/6, 0.05, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124658d7",
   "metadata": {},
   "source": [
    "![nerve damage](assets/graph_nerve_damage.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e245fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = make_y_files_graph(G, set_scaling=True)\n",
    "w.set_edge_label_mapping('relation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e9843",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3315ca8",
   "metadata": {},
   "source": [
    "It seems neck injury causes nerve damage; more so than the dataset's general distribution. Many locations such as MOBILE, STREET, FARM have not reported this type of incident. Many of the body part are not affected by this injury as shown by isolated nodes in the graph. Male and Female are equally likely to be affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a94a52-6962-4c30-806d-47b02995c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('done....ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f97a7e-6aa8-4b22-be42-b88092a53622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
